{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOA56Oszb12Esu3g5xbp/xF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashish1610dhiman/CSE8803_DLT_Project/blob/main/2_model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nflows"
      ],
      "metadata": {
        "id": "A_xrprrtLyg5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "uxsfAu4rIUss"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions import StandardNormal\n",
        "from nflows.transforms import CompositeTransform, ReversePermutation, MaskedAffineAutoregressiveTransform\n",
        "from nflows.nn.nets import ResidualNet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exp params\n",
        "VERSION = \"v0\" #meta for saving\n",
        "drive.mount('/content/drive')\n",
        "EXP_PATH = '/content/drive/My Drive/call_prices_conditional_flow/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlUOiYROJuNk",
        "outputId": "1756b81a-2397-497f-8072-1360598700ba"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Load Dataset and create DataLoader"
      ],
      "metadata": {
        "id": "492_ewgcKJqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PackedOptionDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.X = data[\"X\"]\n",
        "        self.Y = data[\"Y\"]\n",
        "        self.T = data[\"T\"]\n",
        "        self.meta = data[\"meta\"]\n",
        "        self.is_test = data.get(\"is_test\", torch.zeros(len(self.X), dtype=torch.bool))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"X\": self.X[idx],\n",
        "            \"Y\": self.Y[idx],\n",
        "            \"T\": self.T[idx],\n",
        "            \"meta\": self.meta[idx],\n",
        "            \"is_test\": self.is_test[idx]\n",
        "        }"
      ],
      "metadata": {
        "id": "MSs7hGmpJuQ5"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{EXP_PATH}/train_test_val_dataste_{VERSION}.pkl\", \"rb\") as f:\n",
        "    dataset_splits = pickle.load(f)"
      ],
      "metadata": {
        "id": "EJu_zfZ9JuUG"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read data dict from google colab\n",
        "with open(f\"{EXP_PATH}/dataset_{VERSION}.pkl\", 'rb') as f:\n",
        "    combined_data_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "weRIof94fXbH"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloaders"
      ],
      "metadata": {
        "id": "9SlcOoNfKag0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_splits[\"train\"][\"meta\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK1DjJUqfDOY",
        "outputId": "17cfc092-bb58-4ba3-ffbb-3fa6d77bc8ea"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0500, 0.1400, 4.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = PackedOptionDataset(dataset_splits[\"train\"])\n",
        "val_set   = PackedOptionDataset(dataset_splits[\"val\"])\n",
        "test_set  = PackedOptionDataset(dataset_splits[\"test\"])"
      ],
      "metadata": {
        "id": "wwGLQmplJuXT"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64  # or any size you prefer\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set, batch_size=64, shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set, batch_size=64, shuffle=False, num_workers=2, pin_memory=True\n",
        ")\n",
        "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Train size: {len(train_loader.dataset)} | Val: {len(val_loader.dataset)} | Test: {len(test_loader.dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvyNGCbqJuae",
        "outputId": "8378ed9a-08ac-4474-8eb0-ede51d33f33c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 479294 | Val: 102706 | Test: 105000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create & train model"
      ],
      "metadata": {
        "id": "5mmgBX2MKzRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Embedding network ---\n",
        "class EmbeddingNet(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "ylfw6P2rJudq"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_conditional_flow(y_dim, context_dim, hidden_dim=64, num_blocks=4):\n",
        "    transforms = []\n",
        "\n",
        "    for _ in range(num_blocks):\n",
        "        transforms.append(\n",
        "            MaskedAffineAutoregressiveTransform(\n",
        "                features=y_dim,\n",
        "                hidden_features=hidden_dim,\n",
        "                context_features=context_dim,\n",
        "                num_blocks=2,\n",
        "                use_residual_blocks=True,\n",
        "                activation=torch.relu,\n",
        "                dropout_probability=0.0,\n",
        "                random_mask=False\n",
        "            )\n",
        "        )\n",
        "        transforms.append(ReversePermutation(features=y_dim))\n",
        "\n",
        "    transform = CompositeTransform(transforms)\n",
        "    base_dist = StandardNormal([y_dim])\n",
        "\n",
        "    return Flow(transform=transform, distribution=base_dist)"
      ],
      "metadata": {
        "id": "L2Khv_3YJug7"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingFlowModel(nn.Module):\n",
        "    def __init__(self, x_dim, y_dim, embed_dim=32, flow_hidden=64, flow_blocks=4):\n",
        "        super().__init__()\n",
        "        self.embedding_net = EmbeddingNet(input_dim=x_dim, embed_dim=embed_dim)\n",
        "        self.flow = create_conditional_flow(\n",
        "            y_dim=y_dim, context_dim=embed_dim,\n",
        "            hidden_dim=flow_hidden, num_blocks=flow_blocks\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        context = self.embedding_net(x)\n",
        "        log_prob = self.flow.log_prob(inputs=y, context=context)\n",
        "        return log_prob\n",
        "\n",
        "    def sample(self, x, num_samples=1):\n",
        "        context = self.embedding_net(x)\n",
        "        return self.flow.sample(num_samples=num_samples, context=context)"
      ],
      "metadata": {
        "id": "2VVqbwUnJukV"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initialize model ---\n",
        "x_dim = train_set.X.shape[1]\n",
        "y_dim = train_set.Y.shape[1]\n",
        "\n",
        "model = EmbeddingFlowModel(x_dim=x_dim, y_dim=y_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "n_epochs = 10\n",
        "log_interval = 1"
      ],
      "metadata": {
        "id": "s21dHe2TJuny"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Z4GsPuNiUoou"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    #Training\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        x = batch[\"X\"].to(\"cuda\")\n",
        "        y = batch[\"Y\"].to(\"cuda\")\n",
        "        log_prob = model(x, y)\n",
        "        loss = -log_prob.mean()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x = batch[\"X\"].to(\"cuda\")\n",
        "            y = batch[\"Y\"].to(\"cuda\")\n",
        "            log_prob = model(x, y)\n",
        "            val_loss += (-log_prob.mean().item()) * x.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    print(f\"Epoch {epoch:02d} | Train NLL: {train_loss:.4f} | Val NLL: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "ILgzxauEJurQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Validation set metrics"
      ],
      "metadata": {
        "id": "NOyHdxTIUZPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "model.eval()\n",
        "all_y_true, all_y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        x = batch[\"X\"].to(device, non_blocking=True)\n",
        "        y_true = batch[\"Y\"].to(device, non_blocking=True)\n",
        "\n",
        "        x_embed = model.embedding_net(x)\n",
        "\n",
        "        # Use shape from target\n",
        "        batch_size, y_dim = y_true.shape\n",
        "        base_mean = torch.zeros((batch_size, y_dim), device=device)\n",
        "\n",
        "        # 🔧 Unpack tuple\n",
        "        y_pred = model.flow.sample(num_samples=1, context=x_embed)  # shape: (1, B, y_dim)\n",
        "        y_pred = y_pred.squeeze(0)  # remove sample dim\n",
        "\n",
        "\n",
        "        all_y_true.append(y_true.cpu())\n",
        "        all_y_pred.append(y_pred.cpu())\n"
      ],
      "metadata": {
        "id": "O8e-ZyLmUXne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack and compute metrics\n",
        "y_true_full = torch.cat(all_y_true).numpy()\n",
        "y_pred_full = torch.cat(all_y_pred).numpy()\n",
        "\n",
        "mse = mean_squared_error(y_true_full, y_pred_full)\n",
        "mae = mean_absolute_error(y_true_full, y_pred_full)\n",
        "\n",
        "print(f\"📊 Validation MSE: {mse:.4f} | MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "zAdqovqvUXtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_loader)"
      ],
      "metadata": {
        "id": "RFmKBU2IV_0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_loader.dataset)"
      ],
      "metadata": {
        "id": "4khhWZrWWK17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "102706/64"
      ],
      "metadata": {
        "id": "OP2XkoTpWTDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader"
      ],
      "metadata": {
        "id": "sUVhin1JUXwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_y_pred)"
      ],
      "metadata": {
        "id": "duZ_vyKKUX0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set.meta"
      ],
      "metadata": {
        "id": "C4tjYvzMe5jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BURNIN_WINDOW=50"
      ],
      "metadata": {
        "id": "0DI-Zsjrfx1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume one prediction\n",
        "idx = 1\n",
        "y_pred = y_pred_full[idx]        # shape (M,)\n",
        "print(y_pred)\n",
        "meta   = val_set.meta[idx]       # (mu, sigma, path_id)\n",
        "t_idx  = val_set.T[idx].item()   # time index in call_prices\n",
        "\n",
        "mu, sigma, path_id = meta.detach().cpu().numpy()\n",
        "gbm_path = combined_data_dict[(0.14, 0.19)][\"gbm_paths\"]  # shape (n_steps, N_paths)\n",
        "\n",
        "# Map prediction back to true path in GBM\n",
        "gbm_t = t_idx + BURNIN_WINDOW\n",
        "y_true_actual = y_true_full[idx]"
      ],
      "metadata": {
        "id": "Ne7LToflWLnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(y_true_actual, label=\"True future spot\")\n",
        "# plt.plot(y_pred, label=\"Predicted\", linestyle=\"--\")\n",
        "plt.title(f\"Path {path_id} | μ={mu}, σ={sigma} | t={gbm_t}\")\n",
        "plt.xlabel(\"Future time step\")\n",
        "plt.ylabel(\"Spot price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DiJ6jybaUX3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfnXsZiSUX6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVQy_riBUX-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCoOaNwnUYB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XoNb8lvUYFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}